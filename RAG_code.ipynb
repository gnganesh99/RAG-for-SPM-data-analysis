{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8b13da",
   "metadata": {},
   "source": [
    "# RAG for STM data analysis\n",
    "\n",
    "Here we developed a RAG agent to interface with custom data analysis code. \n",
    "\n",
    "The user interacts with the agent to analyse STM data. The agent then provides new code that can be used for plotting data.\n",
    "\n",
    "We use the \"test_rag_output.ipynb\" to the RAG prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fdc46",
   "metadata": {},
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f563a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ggn\\1_py_scripts\\RAG\\chat_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718af2a6",
   "metadata": {},
   "source": [
    "## Function for persist_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def get_persist_dir(\n",
    "    base_dir: str | Path,\n",
    "    basename: str,\n",
    "    *,\n",
    "    new_persist: bool = False,\n",
    "    create: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find (or create) a persist directory under base_dir.\n",
    "\n",
    "    Looks for directories named: f\"{basename}_{run_id}\" where run_id is an int.\n",
    "    - If new_persist=False: returns the latest existing folder if found, else basename_0\n",
    "    - If new_persist=True : returns a new folder with run_id = (latest + 1) or 0 if none exist\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir).expanduser().resolve()\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pattern = re.compile(rf\"^{re.escape(basename)}_(\\d+)$\")\n",
    "\n",
    "    max_run_id: Optional[int] = None\n",
    "    for p in base_path.iterdir():\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        m = pattern.match(p.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        run_id = int(m.group(1))\n",
    "        if max_run_id is None or run_id > max_run_id:\n",
    "            max_run_id = run_id\n",
    "\n",
    "    if max_run_id is None:\n",
    "        next_id = 0\n",
    "    else:\n",
    "        next_id = (max_run_id + 1) if new_persist else max_run_id\n",
    "\n",
    "    persist_path = base_path / f\"{basename}_{next_id}\"\n",
    "\n",
    "    if create:\n",
    "        persist_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return persist_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65a218",
   "metadata": {},
   "source": [
    "## RAG chain function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d401b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_chain(folder_path: str, persist_basename: str, \n",
    "                  new_persist: bool = False, chunk_size: int = 1200, chunk_overlap: int = 200, \n",
    "                  model: str = \"gpt-5\", temperature: float = 0.0, api_key: Optional[str] = None):\n",
    "    \n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) Environment variables\n",
    "    # -----------------------------\n",
    "    # Make sure OPENAI_API_KEY is set in your environment before running\n",
    "    if api_key is None:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"\"\n",
    "    else:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    print(\"OPENAI_API_KEY starts with:\", (os.environ[\"OPENAI_API_KEY\"][:5] + \"...\") if os.environ[\"OPENAI_API_KEY\"] else \"Not Set\")\n",
    "\n",
    "    # Disable LangSmith tracing (prevents 401 errors if you don't use LangSmith)\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"rag-code-search\"\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) Text splitting / chunking (tuned for code)\n",
    "    # -----------------------------\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) Load .py and .ipynb from a folder\n",
    "    # -----------------------------\n",
    "    def load_py_file(path: Path) -> Document:\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        return Document(page_content=text, metadata={\"source\": str(path), \"type\": \"py\"})\n",
    "\n",
    "    def load_ipynb_file(path: Path) -> Document:\n",
    "        nb = json.loads(path.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "\n",
    "        parts = []\n",
    "        for cell in nb.get(\"cells\", []):\n",
    "            cell_type = cell.get(\"cell_type\", \"\")\n",
    "            src = cell.get(\"source\", [])\n",
    "            if isinstance(src, list):\n",
    "                src = \"\".join(src)\n",
    "            src = (src or \"\").strip()\n",
    "            if not src:\n",
    "                continue\n",
    "\n",
    "            # Keep both markdown + code, but label them\n",
    "            if cell_type == \"code\":\n",
    "                parts.append(\"# --- notebook code cell ---\\n\" + src)\n",
    "            elif cell_type == \"markdown\":\n",
    "                parts.append(\"# --- notebook markdown cell ---\\n\" + src)\n",
    "\n",
    "        text = \"\\n\\n\".join(parts)\n",
    "        return Document(page_content=text, metadata={\"source\": str(path), \"type\": \"ipynb\"})\n",
    "\n",
    "    def load_code_documents(folder_path: str) -> List[Document]:\n",
    "        folder = Path(folder_path)\n",
    "        documents: List[Document] = []\n",
    "\n",
    "        for path in folder.rglob(\"*\"):\n",
    "            if path.is_dir():\n",
    "                continue\n",
    "\n",
    "            suffix = path.suffix.lower()\n",
    "            if suffix == \".py\":\n",
    "                documents.append(load_py_file(path))\n",
    "            elif suffix == \".ipynb\":\n",
    "                documents.append(load_ipynb_file(path))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return documents\n",
    "\n",
    "\n",
    "\n",
    "    documents = load_code_documents(folder_path)\n",
    "    print(f\"Loaded {len(documents)} code documents from {folder_path!r} (.py + .ipynb).\")\n",
    "\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(splits)} chunks.\")\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) Embedding + Vector store (persisted)\n",
    "    # -----------------------------\n",
    "    #PERSIST_DIR = Path(\"./chroma_db_code_1\")\n",
    "    PERSIST_DIR = get_persist_dir(\"./persists/\", persist_basename, new_persist=new_persist)\n",
    "\n",
    "\n",
    "    COLLECTION_NAME = \"code_collection\"\n",
    "\n",
    "    embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    # IMPORTANT: if you run from_documents every time, you rebuild the DB.\n",
    "    # The logic below loads existing DB if present, otherwise builds it.\n",
    "    db_file = Path(PERSIST_DIR) / \"chroma.sqlite3\"\n",
    "    if db_file.exists():\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            persist_directory=PERSIST_DIR,\n",
    "            embedding_function=embedding_function,\n",
    "        )\n",
    "        print(f\"Loaded existing vector DB from {PERSIST_DIR!r}.\")\n",
    "    else:\n",
    "        if not splits:\n",
    "            raise ValueError(\"No code chunks found. Check that ./docs contains .py or .ipynb files.\")\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embedding_function,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            persist_directory=PERSIST_DIR,\n",
    "        )\n",
    "        #vectorstore.persist()\n",
    "        print(f\"Created and persisted vector DB at {PERSIST_DIR!r}.\")\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) Retriever\n",
    "    # -----------------------------\n",
    "    #retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 6, \"fetch_k\": 20, \"lambda_mult\": 0.5}\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6) RAG chain that outputs PYTHON CODE ONLY (as a string)\n",
    "    # -----------------------------\n",
    "    def docs2str(docs: List[Document]) -> str:\n",
    "        # Keep source hints so the model can reference repo utilities if they exist\n",
    "        out = []\n",
    "        for d in docs:\n",
    "            src = d.metadata.get(\"source\", \"unknown\")\n",
    "            out.append(f\"### SOURCE: {src}\\n{d.page_content}\")\n",
    "        return \"\\n\\n\".join(out)\n",
    "\n",
    "    template = \"\"\"You are a coding assistant.\n",
    "\n",
    "    You must write Python code ONLY (no markdown fences, no explanations).\n",
    "    Your output must be a single Python script as plain text.\n",
    "\n",
    "    CONTEXT (repository code snippets):\n",
    "    {context}\n",
    "\n",
    "    Task:\n",
    "    {question}\n",
    "\n",
    "    Python code:\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | docs2str, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa506a9",
   "metadata": {},
   "source": [
    "## Write code to py-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37385319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_generated_code_to_file(\n",
    "    code_str: str,\n",
    "    filename: str = \"main_rag_test.py\",\n",
    "    encoding: str = \"utf-8\",\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Overwrite `filename` with `code_str`. Creates the file if it doesn't exist.\n",
    "    Returns the Path to the written file.\n",
    "    \"\"\"\n",
    "    path = Path(filename).expanduser().resolve()\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Ensure we're writing a string (some chains return dicts / messages)\n",
    "    if not isinstance(code_str, str):\n",
    "        code_str = str(code_str)\n",
    "\n",
    "    # Add a trailing newline for nicer diffs/editors\n",
    "    if not code_str.endswith(\"\\n\"):\n",
    "        code_str += \"\\n\"\n",
    "\n",
    "    path.write_text(code_str, encoding=encoding)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ca18a",
   "metadata": {},
   "source": [
    "# 2D image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9312be",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_persist = False # Set to True to create a new persist directory. Set to True while creating new db.\n",
    "folder_path = \"./stm_data_code_sample/2D_image_data\"\n",
    "\n",
    "chunk_size = 1200\n",
    "chunk_overlap = 200\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "persist_basename = \"chroma_db_code\"\n",
    "\n",
    "model = \"gpt-5\"\n",
    "temperature = 0\n",
    "\n",
    "task = \"\"\"\n",
    "Write code to plot the Z-height image of the file \"image.sxm\" located in \"./stm_data_code_sample/2D_image_data\".\n",
    "- Import necessary libraries\n",
    "- The script should:\n",
    "  1) load ./stm_data_code_sample/2D_image_data/image.sxm\n",
    "  2) import stm_utils from ./stm_data_code_sample/2D_image_data\n",
    "  2) extract the Z/height channel (or the most appropriate topography channel)\n",
    "  3) plot it with matplotlib imshow + colorbar\n",
    "  4) Do not save the image to file, just show it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c0eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY starts with: sk-pr...\n",
      "Loaded 3 code documents from './stm_data_code_sample/2D_image_data' (.py + .ipynb).\n",
      "Split into 6 chunks.\n",
      "Loaded existing vector DB from WindowsPath('C:/Users/ggn/1_py_scripts/RAG/RAG_data_analysis_hackathon_2025/persists/chroma_db_code_10').\n",
      "\n",
      "===== GENERATED PYTHON CODE (STRING) =====\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def get_script_dir():\n",
      "    try:\n",
      "        return os.path.dirname(os.path.abspath(__file__))\n",
      "    except NameError:\n",
      "        return os.getcwd()\n",
      "\n",
      "script_dir = get_script_dir()\n",
      "data_dir = os.path.join(script_dir, \"stm_data_code_sample\", \"2D_image_data\")\n",
      "sys.path.insert(0, data_dir)\n",
      "\n",
      "from stm_utils import Sxm_Image\n",
      "\n",
      "filepath = os.path.join(data_dir, \"image.sxm\")\n",
      "im = Sxm_Image(filepath)\n",
      "\n",
      "channels = im.get_channels()\n",
      "\n",
      "def channel_score(ch):\n",
      "    name = ch.lower()\n",
      "    if name.startswith('z'):\n",
      "        base = 0\n",
      "    elif 'topo' in name or 'topography' in name:\n",
      "        base = 10\n",
      "    elif 'height' in name:\n",
      "        base = 20\n",
      "    else:\n",
      "        base = 100\n",
      "    if name.endswith('fwd') or '_fwd' in name:\n",
      "        base -= 1\n",
      "    elif name.endswith('bkd') or '_bkd' in name or 'bwd' in name or 'back' in name:\n",
      "        base += 1\n",
      "    return base\n",
      "\n",
      "selected_channel = None\n",
      "if isinstance(channels, (list, tuple)) and len(channels) > 0:\n",
      "    if 'Z_Fwd' in channels:\n",
      "        selected_channel = 'Z_Fwd'\n",
      "    else:\n",
      "        scored = sorted(channels, key=lambda c: (channel_score(c), c))\n",
      "        # Prefer a channel that is likely topography (score < 100)\n",
      "        if channel_score(scored[0]) < 100:\n",
      "            selected_channel = scored[0]\n",
      "        else:\n",
      "            selected_channel = scored[0]\n",
      "\n",
      "# Fallback to default if selection failed\n",
      "if selected_channel is None:\n",
      "    img = im.image()\n",
      "    title = \"Z_Fwd\"\n",
      "else:\n",
      "    img = im.image(selected_channel)\n",
      "    title = selected_channel\n",
      "\n",
      "plt.imshow(img, origin='lower')\n",
      "plt.colorbar()\n",
      "plt.title(title)\n",
      "plt.axis('off')\n",
      "plt.show()\n"
     ]
    }
   ],
   "source": [
    "rag_chain = get_rag_chain(\n",
    "    folder_path=folder_path,\n",
    "    persist_basename=persist_basename,\n",
    "    new_persist=new_persist,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "response_code_str = rag_chain.invoke(task)\n",
    "\n",
    "print(\"\\n===== GENERATED PYTHON CODE (STRING) =====\\n\")\n",
    "print(response_code_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbf8a8",
   "metadata": {},
   "source": [
    "## Test the code\n",
    "Write the code to \"main_rag_test.py\". Overwrites if already exists.\n",
    "\n",
    "Test it by running \"python main_rag_test.py\" on terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b5e9d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/ggn/1_py_scripts/RAG/RAG_data_analysis_hackathon_2025/main_rag_test.py')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_generated_code_to_file(\n",
    "    code_str=response_code_str,\n",
    "    filename=\"main_rag_test.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182deb4",
   "metadata": {},
   "source": [
    "# 3D hyperspectral data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d38721",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_persist = True # Set to True to create a new persist directory. Set to True while creating new db.\n",
    "folder_path = \"./stm_data_code_sample/3D_hyperspectral_data\"\n",
    "\n",
    "# Chunk size and overlap hyperparameters\n",
    "chunk_size = 1200\n",
    "chunk_overlap = 200\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "persist_basename = \"chroma_db_code3d\"\n",
    "\n",
    "model = \"gpt-5\"\n",
    "temperature = 0  #Vary in the range 0-2.\n",
    "\n",
    "task = \"\"\"\n",
    "Write code to plot the current map at a probe bias of 1.2 V for the cits_data.3ds\".\n",
    "- Import necessary libraries\n",
    "- The script should:\n",
    "  1) load ./stm_data_code_sample/3D_hyperspectral_data/cits_data.3ds\n",
    "  2) extract the Z/height channel (or the most appropriate topography channel)\n",
    "  3) plot it with matplotlib imshow + colorbar\n",
    "  4) Do not save the image to file, just show it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64fd20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY starts with: sk-pr...\n",
      "Loaded 2 code documents from './stm_data_code_sample/3D_hyperspectral_data' (.py + .ipynb).\n",
      "Split into 7 chunks.\n",
      "Created and persisted vector DB at WindowsPath('C:/Users/ggn/1_py_scripts/RAG/RAG_data_analysis_hackathon_2025/persists/chroma_db_code3d_2').\n",
      "\n",
      "===== GENERATED PYTHON CODE (STRING) =====\n",
      "\n",
      "import os\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import stmpy\n",
      "\n",
      "def get_topography(smd):\n",
      "    # Try common attribute names\n",
      "    for name in ['topo', 'topography', 'z', 'Z', 'Topo', 'Topography', 'height', 'Height']:\n",
      "        if hasattr(smd, name):\n",
      "            topo = getattr(smd, name)\n",
      "            topo = np.asarray(topo)\n",
      "            if topo.ndim == 2:\n",
      "                return topo\n",
      "            if topo.ndim >= 3:\n",
      "                return topo[0]\n",
      "    # Try within dict-like attributes\n",
      "    for obj in [getattr(smd, 'signals', None), getattr(smd, 'grid', None), getattr(smd, '__dict__', None)]:\n",
      "        if isinstance(obj, dict):\n",
      "            for k, v in obj.items():\n",
      "                lk = str(k).lower()\n",
      "                if any(t in lk for t in ['topo', 'height', 'topography', ' z', 'z (', '(z)']):\n",
      "                    arr = np.asarray(v)\n",
      "                    if arr.ndim == 2:\n",
      "                        return arr\n",
      "                    if arr.ndim >= 3:\n",
      "                        return arr[0]\n",
      "    return None\n",
      "\n",
      "def nearest_index(value, array):\n",
      "    array = np.asarray(array, dtype=float).ravel()\n",
      "    return int(np.argmin(np.abs(array - float(value))))\n",
      "\n",
      "def main():\n",
      "    filepath = './stm_data_code_sample/3D_hyperspectral_data/cits_data.3ds'\n",
      "    smd = stmpy.load(filepath, biasOffset=False)\n",
      "\n",
      "    # Extract topography (Z/height)\n",
      "    topo = get_topography(smd)\n",
      "\n",
      "    # Current map at probe bias 1.2 V\n",
      "    V = np.asarray(smd.en, dtype=float).ravel()\n",
      "    probe_bias = 1.2\n",
      "    iv = nearest_index(probe_bias, V)\n",
      "    V_actual = V[iv]\n",
      "\n",
      "    Icube = np.asarray(smd.I)\n",
      "    # Expect shape (nV, nx, ny); if not, try to reconcile basic alternatives\n",
      "    if Icube.ndim != 3:\n",
      "        raise ValueError(\"Unexpected current data dimensionality.\")\n",
      "    if Icube.shape[0] == V.size:\n",
      "        current_map = Icube[iv]\n",
      "    elif Icube.shape[-1] == V.size:\n",
      "        current_map = np.moveaxis(Icube, -1, 0)[iv]\n",
      "    else:\n",
      "        # Fallback: assume first axis corresponds to energy\n",
      "        current_map = Icube[iv]\n",
      "\n",
      "    # Plot\n",
      "    if topo is not None:\n",
      "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
      "        im0 = axes[0].imshow(topo, origin='lower', aspect='auto')\n",
      "        axes[0].set_title('Topography (Z/height)')\n",
      "        plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
      "        im1 = axes[1].imshow(current_map, origin='lower', aspect='auto')\n",
      "        axes[1].set_title(f'Current map at {V_actual:.3f} V')\n",
      "        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
      "        plt.tight_layout()\n",
      "    else:\n",
      "        plt.figure(figsize=(5, 4))\n",
      "        im1 = plt.imshow(current_map, origin='lower', aspect='auto')\n",
      "        plt.title(f'Current map at {V_actual:.3f} V')\n",
      "        plt.colorbar(im1, fraction=0.046, pad=0.04)\n",
      "        plt.tight_layout()\n",
      "\n",
      "    plt.show()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "rag_chain = get_rag_chain(\n",
    "    folder_path=folder_path,\n",
    "    persist_basename=persist_basename,\n",
    "    new_persist=new_persist,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "response_code_str = rag_chain.invoke(task)\n",
    "\n",
    "print(\"\\n===== GENERATED PYTHON CODE (STRING) =====\\n\")\n",
    "print(response_code_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85669cef",
   "metadata": {},
   "source": [
    "## Test the code\n",
    "Write the code to \"main_rag_test.py\". Overwrites if already exists.\n",
    "\n",
    "Test it by running \"python main_rag_test.py\" on terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75e8720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/ggn/1_py_scripts/RAG/RAG_data_analysis_hackathon_2025/main_rag_test.py')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_generated_code_to_file(\n",
    "    code_str=response_code_str,\n",
    "    filename=\"main_rag_test.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cee9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat_env_kernel",
   "language": "python",
   "name": "chat_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
