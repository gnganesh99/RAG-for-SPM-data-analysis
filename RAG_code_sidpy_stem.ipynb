{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8b13da",
   "metadata": {},
   "source": [
    "# RAG for STM data analysis\n",
    "\n",
    "Here we developed a RAG agent to interface with custom data analysis code. \n",
    "\n",
    "The user interacts with the agent to analyse STM data. The agent then provides new code that can be used for plotting data.\n",
    "\n",
    "We use the \"test_rag_output.ipynb\" to the RAG prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fdc46",
   "metadata": {},
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f563a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144b4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "718af2a6",
   "metadata": {},
   "source": [
    "## Function for persist_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f910600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def get_persist_dir(\n",
    "    base_dir: str | Path,\n",
    "    basename: str,\n",
    "    *,\n",
    "    new_persist: bool = False,\n",
    "    create: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Find (or create) a persist directory under base_dir.\n",
    "\n",
    "    Looks for directories named: f\"{basename}_{run_id}\" where run_id is an int.\n",
    "    - If new_persist=False: returns the latest existing folder if found, else basename_0\n",
    "    - If new_persist=True : returns a new folder with run_id = (latest + 1) or 0 if none exist\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir).expanduser().resolve()\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pattern = re.compile(rf\"^{re.escape(basename)}_(\\d+)$\")\n",
    "\n",
    "    max_run_id: Optional[int] = None\n",
    "    for p in base_path.iterdir():\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        m = pattern.match(p.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        run_id = int(m.group(1))\n",
    "        if max_run_id is None or run_id > max_run_id:\n",
    "            max_run_id = run_id\n",
    "\n",
    "    if max_run_id is None:\n",
    "        next_id = 0\n",
    "    else:\n",
    "        next_id = (max_run_id + 1) if new_persist else max_run_id\n",
    "\n",
    "    persist_path = base_path / f\"{basename}_{next_id}\"\n",
    "\n",
    "    if create:\n",
    "        persist_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return persist_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65a218",
   "metadata": {},
   "source": [
    "## RAG chain function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d401b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_chain(folder_path: str, persist_basename: str, \n",
    "                  new_persist: bool = False, chunk_size: int = 1200, chunk_overlap: int = 200, \n",
    "                  model: str = \"gpt-5\", temperature: int = 0, api_key: Optional[str] = None):\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING get_rag_chain\")\n",
    "    print(f\"Parameters: folder_path={folder_path}, persist_basename={persist_basename}\")\n",
    "    print(f\"new_persist={new_persist}, chunk_size={chunk_size}, chunk_overlap={chunk_overlap}\")\n",
    "    print(f\"model={model}, temperature={temperature}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) Environment variables\n",
    "    # -----------------------------\n",
    "    print(\"\\n[1/6] Setting up environment variables...\")\n",
    "    # Make sure OPENAI_API_KEY is set in your environment before running\n",
    "    if api_key is None:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"\"\n",
    "    else:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    print(\"OPENAI_API_KEY starts with:\", (os.environ[\"OPENAI_API_KEY\"][:5] + \"...\") if os.environ[\"OPENAI_API_KEY\"] else \"Not Set\")\n",
    "\n",
    "    # Disable LangSmith tracing (prevents 401 errors if you don't use LangSmith)\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"rag-code-search\"\n",
    "    print(\"✓ Environment variables configured\")\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) Text splitting / chunking (tuned for code)\n",
    "    # -----------------------------\n",
    "    print(\"\\n[2/6] Creating text splitter...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "    print(\"✓ Text splitter created\")\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) Load .py and .ipynb from a folder\n",
    "    # -----------------------------\n",
    "    print(\"\\n[3/6] Loading code documents...\")\n",
    "    \n",
    "    def load_py_file(path: Path) -> Document:\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        return Document(page_content=text, metadata={\"source\": str(path), \"type\": \"py\"})\n",
    "\n",
    "    def load_ipynb_file(path: Path) -> Document:\n",
    "        nb = json.loads(path.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "\n",
    "        parts = []\n",
    "        for cell in nb.get(\"cells\", []):\n",
    "            cell_type = cell.get(\"cell_type\", \"\")\n",
    "            src = cell.get(\"source\", [])\n",
    "            if isinstance(src, list):\n",
    "                src = \"\".join(src)\n",
    "            src = (src or \"\").strip()\n",
    "            if not src:\n",
    "                continue\n",
    "\n",
    "            # Keep both markdown + code, but label them\n",
    "            if cell_type == \"code\":\n",
    "                parts.append(\"# --- notebook code cell ---\\n\" + src)\n",
    "            elif cell_type == \"markdown\":\n",
    "                parts.append(\"# --- notebook markdown cell ---\\n\" + src)\n",
    "\n",
    "        text = \"\\n\\n\".join(parts)\n",
    "        return Document(page_content=text, metadata={\"source\": str(path), \"type\": \"ipynb\"})\n",
    "\n",
    "    def load_code_documents(folder_path: str) -> List[Document]:\n",
    "        folder = Path(folder_path)\n",
    "        documents: List[Document] = []\n",
    "\n",
    "        for path in folder.rglob(\"*\"):\n",
    "            if path.is_dir():\n",
    "                continue\n",
    "\n",
    "            suffix = path.suffix.lower()\n",
    "            if suffix == \".py\":\n",
    "                documents.append(load_py_file(path))\n",
    "            elif suffix == \".ipynb\":\n",
    "                documents.append(load_ipynb_file(path))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        return documents\n",
    "\n",
    "\n",
    "\n",
    "    documents = load_code_documents(folder_path)\n",
    "    print(f\"✓ Loaded {len(documents)} code documents from {folder_path!r} (.py + .ipynb).\")\n",
    "\n",
    "    print(\"  Splitting documents into chunks...\")\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    print(f\"✓ Split into {len(splits)} chunks.\")\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4) Embedding + Vector store (persisted)\n",
    "    # -----------------------------\n",
    "    print(\"\\n[4/6] Setting up vector store...\")\n",
    "    #PERSIST_DIR = Path(\"./chroma_db_code_1\")\n",
    "    PERSIST_DIR = get_persist_dir(\"./persists/\", persist_basename, new_persist=new_persist)\n",
    "    print(f\"  Persist directory: {PERSIST_DIR}\")\n",
    "\n",
    "    COLLECTION_NAME = \"code_collection\"\n",
    "\n",
    "    print(\"  Creating embedding function...\")\n",
    "    embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    print(\"✓ Embedding function created\")\n",
    "\n",
    "    # IMPORTANT: if you run from_documents every time, you rebuild the DB.\n",
    "    # The logic below loads existing DB if present, otherwise builds it.\n",
    "    db_file = Path(PERSIST_DIR) # / \"chroma.sqlite3\"\n",
    "    if db_file.exists():\n",
    "        print(f\"  Loading existing vector DB from {PERSIST_DIR}...\")\n",
    "        print(\"  ⚠️  WARNING: If on OneDrive, this may cause kernel crash!\")\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            persist_directory=PERSIST_DIR,\n",
    "            embedding_function=embedding_function,\n",
    "        )\n",
    "        print(f\"✓ Loaded existing vector DB from {PERSIST_DIR!r}.\")\n",
    "    else:\n",
    "        if not splits:\n",
    "            raise ValueError(\"No code chunks found. Check that ./docs contains .py or .ipynb files.\")\n",
    "        print(f\"  Creating new vector DB (this may take a moment)...\")\n",
    "        print(\"  ⚠️  WARNING: If on OneDrive, this may cause kernel crash!\")\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embedding_function,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            persist_directory=PERSIST_DIR,\n",
    "        )\n",
    "        #vectorstore.persist()\n",
    "        print(f\"✓ Created and persisted vector DB at {PERSIST_DIR!r}.\")\n",
    "\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5) Retriever\n",
    "    # -----------------------------\n",
    "    print(\"\\n[5/6] Creating retriever...\")\n",
    "    #retriever = vectorstore.as_retriever(search_kwargs={\"k\": 6})\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 6, \"fetch_k\": 20, \"lambda_mult\": 0.5}\n",
    "    )\n",
    "    print(\"✓ Retriever created with MMR search (k=6, fetch_k=20)\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6) RAG chain that outputs PYTHON CODE ONLY (as a string)\n",
    "    # -----------------------------\n",
    "    print(\"\\n[6/6] Building RAG chain...\")\n",
    "    \n",
    "    def docs2str(docs: List[Document]) -> str:\n",
    "        # Keep source hints so the model can reference repo utilities if they exist\n",
    "        out = []\n",
    "        for d in docs:\n",
    "            src = d.metadata.get(\"source\", \"unknown\")\n",
    "            out.append(f\"### SOURCE: {src}\\n{d.page_content}\")\n",
    "        return \"\\n\\n\".join(out)\n",
    "\n",
    "    template = \"\"\"You are a coding assistant.\n",
    "\n",
    "    You must write Python code ONLY (no markdown fences, no explanations).\n",
    "    Your output must be a single Python script as plain text.\n",
    "\n",
    "    CONTEXT (repository code snippets):\n",
    "    {context}\n",
    "\n",
    "    Task:\n",
    "    {question}\n",
    "\n",
    "    Python code:\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    print(\"  Prompt template created\")\n",
    "\n",
    "    print(f\"  Initializing LLM ({model})...\")\n",
    "    llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "    print(\"✓ LLM initialized\")\n",
    "\n",
    "    print(\"  Assembling chain...\")\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | docs2str, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    print(\"✓ RAG chain assembled\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓✓✓ get_rag_chain completed successfully!\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "    \n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa506a9",
   "metadata": {},
   "source": [
    "## Write code to py-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37385319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_generated_code_to_file(\n",
    "    code_str: str,\n",
    "    prompt_str: str = \"\",\n",
    "    filename: str = \"main_rag_test.py\",\n",
    "    encoding: str = \"utf-8\",\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Overwrite `filename` with `code_str`. Creates the file if it doesn't exist.\n",
    "    Returns the Path to the written file.\n",
    "    \"\"\"\n",
    "    path = Path(filename).expanduser().resolve()\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Ensure we're writing a string (some chains return dicts / messages)\n",
    "    if not isinstance(code_str, str):\n",
    "        code_str = str(code_str)\n",
    "\n",
    "    # Add a trailing newline for nicer diffs/editors\n",
    "    if not code_str.endswith(\"\\n\"):\n",
    "        code_str += \"\\n\"\n",
    "\n",
    "    path.write_text(f\"# Prompt: \\n \\\"\\\"\\\" {prompt_str} \\n \\\"\\\"\\\" \\n {code_str}\", encoding = encoding)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ca18a",
   "metadata": {},
   "source": [
    "# learn sidpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9312be",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_persist = False # Set to True to create a new persist directory. Set to True while creating new db.\n",
    "folder_path = \"C:/Users/zwx/Documents/sidpy\"\n",
    "\n",
    "chunk_size = 800\n",
    "chunk_overlap = 100\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "persist_basename = \"chroma_db_sidpy\"\n",
    "\n",
    "model = \"gpt-5\"\n",
    "temperature = 0\n",
    "\n",
    "task = \"\"\"\n",
    "Write code to generate a sidpy dataset for a fake 2D image of size 256x256.\\n\n",
    "You can fill the image with random values from 0 to 1.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15bc449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING get_rag_chain\n",
      "Parameters: folder_path=C:/Users/zwx/Documents/sidpy, persist_basename=chroma_db_sidpy\n",
      "new_persist=False, chunk_size=800, chunk_overlap=100\n",
      "model=gpt-5, temperature=0\n",
      "============================================================\n",
      "\n",
      "[1/6] Setting up environment variables...\n",
      "OPENAI_API_KEY starts with: sk-pr...\n",
      "✓ Environment variables configured\n",
      "\n",
      "[2/6] Creating text splitter...\n",
      "✓ Text splitter created\n",
      "\n",
      "[3/6] Loading code documents...\n",
      "✓ Loaded 101 code documents from 'C:/Users/zwx/Documents/sidpy' (.py + .ipynb).\n",
      "  Splitting documents into chunks...\n",
      "✓ Split into 2466 chunks.\n",
      "\n",
      "[4/6] Setting up vector store...\n",
      "  Persist directory: C:\\Users\\zwx\\Documents\\RAG-for-SPM-data-analysis\\persists\\chroma_db_sidpy_0\n",
      "  Creating embedding function...\n",
      "✓ Embedding function created\n",
      "  Loading existing vector DB from C:\\Users\\zwx\\Documents\\RAG-for-SPM-data-analysis\\persists\\chroma_db_sidpy_0...\n",
      "  ⚠️  WARNING: If on OneDrive, this may cause kernel crash!\n",
      "✓ Loaded existing vector DB from WindowsPath('C:/Users/zwx/Documents/RAG-for-SPM-data-analysis/persists/chroma_db_sidpy_0').\n",
      "\n",
      "[5/6] Creating retriever...\n",
      "✓ Retriever created with MMR search (k=6, fetch_k=20)\n",
      "\n",
      "[6/6] Building RAG chain...\n",
      "  Prompt template created\n",
      "  Initializing LLM (gpt-5)...\n",
      "✓ LLM initialized\n",
      "  Assembling chain...\n",
      "✓ RAG chain assembled\n",
      "\n",
      "============================================================\n",
      "✓✓✓ get_rag_chain completed successfully!\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_chain = get_rag_chain(\n",
    "    folder_path=folder_path,\n",
    "    persist_basename=persist_basename,\n",
    "    new_persist=new_persist,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d04a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57021c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000018B3636AE10>, search_type='mmr', search_kwargs={'k': 6, 'fetch_k': 20, 'lambda_mult': 0.5})\n",
       "           | RunnableLambda(docs2str),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='You are a coding assistant.\\n\\n    You must write Python code ONLY (no markdown fences, no explanations).\\n    Your output must be a single Python script as plain text.\\n\\n    CONTEXT (repository code snippets):\\n    {context}\\n\\n    Task:\\n    {question}\\n\\n    Python code:'), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 400000, 'max_output_tokens': 128000, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x0000018B3641E450>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000018B3641F0D0>, root_client=<openai.OpenAI object at 0x0000018B3641E010>, root_async_client=<openai.AsyncOpenAI object at 0x0000018B363D3A50>, model_name='gpt-5', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c0eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ rag_chain created successfully\n",
      "\n",
      "============================================================\n",
      "INVOKING RAG CHAIN\n",
      "============================================================\n",
      "Task: \n",
      "Write code to generate a sidpy dataset for a fake 2D image of size 256x256.\n",
      "\n",
      "You can fill the image...\n",
      "\n",
      "[Step 1/3] Retrieving relevant documents from vector store...\n",
      "  ⚠️  WARNING: ChromaDB query on OneDrive may crash kernel here!\n",
      "\n",
      "[Step 2/3] Calling LLM to generate code...\n",
      "  Using model: gpt-5\n",
      "  This may take 10-30 seconds depending on complexity...\n",
      "\n",
      "[Step 3/3] ✓ Response received successfully!\n",
      "  Generated code length: 1796 characters\n",
      "\n",
      "===== GENERATED PYTHON CODE (STRING) =====\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "# Create random 2D image data\n",
      "np.random.seed(0)\n",
      "image = np.random.rand(256, 256)\n",
      "\n",
      "# Import sidpy Dataset and Dimension with fallbacks for different package structures\n",
      "try:\n",
      "    from sidpy import Dataset, Dimension\n",
      "except Exception:\n",
      "    try:\n",
      "        from sidpy.sid.dataset import Dataset\n",
      "        from sidpy.sid.dimension import Dimension\n",
      "    except Exception as e:\n",
      "        raise ImportError(\"sidpy is required to run this script. Please install sidpy.\") from e\n",
      "\n",
      "# Create the sidpy Dataset\n",
      "if hasattr(Dataset, 'from_array'):\n",
      "    ds = Dataset.from_array(image, name='Fake 2D Image')\n",
      "else:\n",
      "    ds = Dataset(image)\n",
      "    if hasattr(ds, 'title'):\n",
      "        ds.title = 'Fake 2D Image'\n",
      "    elif hasattr(ds, 'name'):\n",
      "        ds.name = 'Fake 2D Image'\n",
      "\n",
      "# Set dataset attributes\n",
      "if hasattr(ds, 'data_type'):\n",
      "    ds.data_type = 'image'\n",
      "if hasattr(ds, 'units'):\n",
      "    ds.units = 'a.u.'\n",
      "if hasattr(ds, 'quantity'):\n",
      "    ds.quantity = 'intensity'\n",
      "\n",
      "# Define and set dimensions\n",
      "y_vals = np.arange(image.shape[0])\n",
      "x_vals = np.arange(image.shape[1])\n",
      "\n",
      "dim_y = Dimension(y_vals, name='Y', units='pixel', quantity='position', dimension_type='spatial')\n",
      "dim_x = Dimension(x_vals, name='X', units='pixel', quantity='position', dimension_type='spatial')\n",
      "\n",
      "if hasattr(ds, 'set_dimension'):\n",
      "    ds.set_dimension(0, dim_y)\n",
      "    ds.set_dimension(1, dim_x)\n",
      "elif hasattr(ds, 'add_dimension'):\n",
      "    ds.add_dimension(dim_y)\n",
      "    ds.add_dimension(dim_x)\n",
      "\n",
      "# Example usage: print a brief summary\n",
      "try:\n",
      "    print(ds)\n",
      "except Exception:\n",
      "    print(\"Created sidpy Dataset:\")\n",
      "    print(f\"  Name/Title: {getattr(ds, 'title', getattr(ds, 'name', 'Unknown'))}\")\n",
      "    print(f\"  Shape: {getattr(ds, 'shape', None)}\")\n",
      "    print(f\"  Data type: {getattr(ds, 'data_type', 'Unknown')}\")\n",
      "    print(f\"  Units: {getattr(ds, 'units', 'Unknown')}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('✓ rag_chain created successfully')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INVOKING RAG CHAIN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Task: {task[:100]}...\" if len(task) > 100 else f\"Task: {task}\")\n",
    "print(\"\\n[Step 1/3] Retrieving relevant documents from vector store...\")\n",
    "print(\"  ⚠️  WARNING: ChromaDB query on OneDrive may crash kernel here!\")\n",
    "\n",
    "try:\n",
    "    print(\"\\n[Step 2/3] Calling LLM to generate code...\")\n",
    "    print(f\"  Using model: {model}\")\n",
    "    print(\"  This may take 10-30 seconds depending on complexity...\")\n",
    "    \n",
    "    response_code_str = rag_chain.invoke(task)\n",
    "    \n",
    "    print(\"\\n[Step 3/3] ✓ Response received successfully!\")\n",
    "    print(f\"  Generated code length: {len(response_code_str)} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n❌ ERROR during rag_chain.invoke()!\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")\n",
    "    import traceback\n",
    "    print(\"\\nFull traceback:\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\"\\n===== GENERATED PYTHON CODE (STRING) =====\\n\")\n",
    "print(response_code_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81b30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== WRITING GENERATED CODE TO FILE =====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== WRITING GENERATED CODE TO FILE =====\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72309bc7",
   "metadata": {},
   "source": [
    "### Troubleshooting rag_chain.invoke() Kernel Crashes\n",
    "\n",
    "If the kernel crashes during `rag_chain.invoke()`, common causes are:\n",
    "\n",
    "1. **OneDrive + SQLite Issue** (Most likely!)\n",
    "   - ChromaDB uses SQLite which conflicts with OneDrive's file syncing\n",
    "   - **Solution A**: Move `persists/` directory outside OneDrive\n",
    "   - **Solution B**: Exclude `persists/` folder from OneDrive sync (right-click folder → Free up space)\n",
    "   - **Solution C**: Use a local temp directory for persists\n",
    "\n",
    "2. **Memory Issues**\n",
    "   - Large vector store or too many retrievals can exhaust memory\n",
    "   - Try reducing `fetch_k` from 20 to 10 in the retriever settings\n",
    "   - Reduce `chunk_size` from 1200 to 800\n",
    "\n",
    "3. **API Issues**\n",
    "   - Invalid API key or rate limits\n",
    "   - Network connectivity problems\n",
    "   - Try changing model from \"gpt-5\" to \"gpt-4\"\n",
    "\n",
    "4. **SQLite Lock**\n",
    "   - Another process accessing the database\n",
    "   - Restart the kernel and try again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbf8a8",
   "metadata": {},
   "source": [
    "## Test the code\n",
    "Write the code to \"main_rag_test.py\". Overwrites if already exists.\n",
    "\n",
    "Test it by running \"python main_rag_test.py\" on terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b5e9d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/zwx/Documents/RAG-for-SPM-data-analysis/test_sidpy_rag.py')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_generated_code_to_file(\n",
    "    code_str=response_code_str,\n",
    "    prompt_str=task,\n",
    "    filename=\"test_sidpy_rag.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182deb4",
   "metadata": {},
   "source": [
    "# 3D hyperspectral data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d38721",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_persist = True # Set to True to create a new persist directory. Set to True while creating new db.\n",
    "folder_path = \"./stm_data_code_sample/3D_hyperspectral_data\"\n",
    "\n",
    "# Chunk size and overlap hyperparameters\n",
    "chunk_size = 1200\n",
    "chunk_overlap = 200\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "persist_basename = \"chroma_db_code3d\"\n",
    "\n",
    "model = \"gpt-5\"\n",
    "temperature = 0\n",
    "\n",
    "task = \"\"\"\n",
    "Write code to plot the current map at a probe bias of 1.2 V for the cits_data.3ds\".\n",
    "- Import necessary libraries\n",
    "- The script should:\n",
    "  1) load ./stm_data_code_sample/3D_hyperspectral_data/cits_data.3ds\n",
    "  2) extract the Z/height channel (or the most appropriate topography channel)\n",
    "  3) plot it with matplotlib imshow + colorbar\n",
    "  4) Do not save the image to file, just show it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64fd20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING get_rag_chain\n",
      "Parameters: folder_path=./stm_data_code_sample/3D_hyperspectral_data, persist_basename=chroma_db_code3d\n",
      "new_persist=True, chunk_size=1200, chunk_overlap=200\n",
      "model=gpt-5, temperature=0\n",
      "============================================================\n",
      "\n",
      "[1/6] Setting up environment variables...\n",
      "OPENAI_API_KEY starts with: sk-pr...\n",
      "✓ Environment variables configured\n",
      "\n",
      "[2/6] Creating text splitter...\n",
      "✓ Text splitter created\n",
      "\n",
      "[3/6] Loading code documents...\n",
      "✓ Loaded 2 code documents from './stm_data_code_sample/3D_hyperspectral_data' (.py + .ipynb).\n",
      "  Splitting documents into chunks...\n",
      "✓ Split into 7 chunks.\n",
      "\n",
      "[4/6] Setting up vector store...\n",
      "  Persist directory: C:\\Users\\zwx\\Documents\\RAG-for-SPM-data-analysis\\persists\\chroma_db_code3d_3\n",
      "  Creating embedding function...\n",
      "✓ Embedding function created\n",
      "  Loading existing vector DB from C:\\Users\\zwx\\Documents\\RAG-for-SPM-data-analysis\\persists\\chroma_db_code3d_3...\n",
      "  ⚠️  WARNING: If on OneDrive, this may cause kernel crash!\n",
      "✓ Embedding function created\n",
      "  Loading existing vector DB from C:\\Users\\zwx\\Documents\\RAG-for-SPM-data-analysis\\persists\\chroma_db_code3d_3...\n",
      "  ⚠️  WARNING: If on OneDrive, this may cause kernel crash!\n",
      "✓ Loaded existing vector DB from WindowsPath('C:/Users/zwx/Documents/RAG-for-SPM-data-analysis/persists/chroma_db_code3d_3').\n",
      "\n",
      "[5/6] Creating retriever...\n",
      "✓ Retriever created with MMR search (k=6, fetch_k=20)\n",
      "\n",
      "[6/6] Building RAG chain...\n",
      "  Prompt template created\n",
      "  Initializing LLM (gpt-5)...\n",
      "✓ LLM initialized\n",
      "  Assembling chain...\n",
      "✓ RAG chain assembled\n",
      "\n",
      "============================================================\n",
      "✓✓✓ get_rag_chain completed successfully!\n",
      "============================================================\n",
      "\n",
      "✓ rag_chain created successfully\n",
      "\n",
      "============================================================\n",
      "INVOKING RAG CHAIN\n",
      "============================================================\n",
      "Task: \n",
      "Write code to plot the current map at a probe bias of 1.2 V for the cits_data.3ds\".\n",
      "- Import necess...\n",
      "\n",
      "[Step 1/3] Retrieving relevant documents from vector store...\n",
      "  ⚠️  WARNING: ChromaDB query on OneDrive may crash kernel here!\n",
      "\n",
      "[Step 2/3] Calling LLM to generate code...\n",
      "  Using model: gpt-5\n",
      "  This may take 10-30 seconds depending on complexity...\n",
      "✓ Loaded existing vector DB from WindowsPath('C:/Users/zwx/Documents/RAG-for-SPM-data-analysis/persists/chroma_db_code3d_3').\n",
      "\n",
      "[5/6] Creating retriever...\n",
      "✓ Retriever created with MMR search (k=6, fetch_k=20)\n",
      "\n",
      "[6/6] Building RAG chain...\n",
      "  Prompt template created\n",
      "  Initializing LLM (gpt-5)...\n",
      "✓ LLM initialized\n",
      "  Assembling chain...\n",
      "✓ RAG chain assembled\n",
      "\n",
      "============================================================\n",
      "✓✓✓ get_rag_chain completed successfully!\n",
      "============================================================\n",
      "\n",
      "✓ rag_chain created successfully\n",
      "\n",
      "============================================================\n",
      "INVOKING RAG CHAIN\n",
      "============================================================\n",
      "Task: \n",
      "Write code to plot the current map at a probe bias of 1.2 V for the cits_data.3ds\".\n",
      "- Import necess...\n",
      "\n",
      "[Step 1/3] Retrieving relevant documents from vector store...\n",
      "  ⚠️  WARNING: ChromaDB query on OneDrive may crash kernel here!\n",
      "\n",
      "[Step 2/3] Calling LLM to generate code...\n",
      "  Using model: gpt-5\n",
      "  This may take 10-30 seconds depending on complexity...\n",
      "\n",
      "[Step 3/3] ✓ Response received successfully!\n",
      "  Generated code length: 8714 characters\n",
      "\n",
      "===== GENERATED PYTHON CODE (STRING) =====\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def find_best_key(keys, prefer='current'):\n",
      "    # Rank available channel keys by preference\n",
      "    ranking = []\n",
      "    for k in keys:\n",
      "        lk = k.lower()\n",
      "        score = 0\n",
      "        if prefer == 'current':\n",
      "            if 'current' in lk:\n",
      "                score += 100\n",
      "            if ' i ' in f' {lk} ' or lk.startswith('i ') or lk.endswith(' i') or lk == 'i':\n",
      "                score += 80\n",
      "            if ' (a)' in lk:\n",
      "                score += 20\n",
      "            if 'liy' in lk or 'lockin y' in lk:\n",
      "                score += 10  # less preferred but acceptable\n",
      "        elif prefer == 'topography':\n",
      "            if 'topography' in lk:\n",
      "                score += 100\n",
      "            if lk.strip() == 'z' or lk.startswith('z ') or ' z ' in f' {lk} ':\n",
      "                score += 90\n",
      "            if 'height' in lk:\n",
      "                score += 80\n",
      "            if '(m)' in lk:\n",
      "                score += 10\n",
      "        ranking.append((score, k))\n",
      "    ranking.sort(reverse=True, key=lambda x: x[0])\n",
      "    best = ranking[0][1] if ranking and ranking[0][0] > 0 else None\n",
      "    return best\n",
      "\n",
      "def load_with_nanonispy(path):\n",
      "    try:\n",
      "        from nanonispy import read\n",
      "    except Exception:\n",
      "        return None\n",
      "    try:\n",
      "        g = read.Grid(path)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to read with nanonispy: {e}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Obtain bias vector\n",
      "    bias = None\n",
      "    for attr in ('bias', 'sweep_signal', 'spectroscopy_axis'):\n",
      "        if hasattr(g, attr):\n",
      "            try:\n",
      "                bias = np.array(getattr(g, attr)).astype(float).ravel()\n",
      "                break\n",
      "            except Exception:\n",
      "                pass\n",
      "    if bias is None:\n",
      "        # Attempt to fetch from header parameters\n",
      "        try:\n",
      "            params = getattr(g, 'params', {})\n",
      "            if 'Bias (V)' in params:\n",
      "                bias = np.array(params['Bias (V)']).astype(float).ravel()\n",
      "        except Exception:\n",
      "            pass\n",
      "    if bias is None:\n",
      "        print(\"Could not determine bias vector from 3ds using nanonispy\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Obtain signals dictionary\n",
      "    signals = None\n",
      "    if hasattr(g, 'signals'):\n",
      "        signals = g.signals\n",
      "    else:\n",
      "        # Some versions may expose channel data differently\n",
      "        cand = []\n",
      "        for attr in dir(g):\n",
      "            if attr.lower() in ('signals', 'channels', 'data'):\n",
      "                obj = getattr(g, attr)\n",
      "                if isinstance(obj, dict):\n",
      "                    signals = obj\n",
      "                    break\n",
      "                else:\n",
      "                    cand.append((attr, type(obj)))\n",
      "        if signals is None:\n",
      "            print(\"Could not find signals in nanonispy Grid object\", file=sys.stderr)\n",
      "            return None\n",
      "\n",
      "    keys = list(signals.keys())\n",
      "    key = find_best_key(keys, prefer='current')\n",
      "    if key is None:\n",
      "        key = find_best_key(keys, prefer='topography')\n",
      "    if key is None:\n",
      "        print(\"No appropriate channel (current or topography) found in 3ds\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    vol = np.array(signals[key])\n",
      "    # Expecting (Ny, Nx, Nz) or (Nx, Ny, Nz) or (Nz, Ny, Nx)\n",
      "    # Try to identify spectroscopic dimension by matching with bias length\n",
      "    vol_shape = vol.shape\n",
      "    dims = len(vol_shape)\n",
      "    if dims != 3:\n",
      "        print(f\"Unexpected data shape for channel '{key}': {vol_shape}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Determine which axis matches bias length\n",
      "    axis_bias = None\n",
      "    for ax in range(3):\n",
      "        if vol_shape[ax] == bias.size:\n",
      "            axis_bias = ax\n",
      "            break\n",
      "    if axis_bias is None:\n",
      "        # As fallback, if last axis matches common case, assume last axis is sweep\n",
      "        axis_bias = 2\n",
      "\n",
      "    return {\n",
      "        'volume': vol,\n",
      "        'bias': bias,\n",
      "        'bias_axis': axis_bias,\n",
      "        'channel_key': key\n",
      "    }\n",
      "\n",
      "def load_with_pyspm(path):\n",
      "    try:\n",
      "        import pySPM\n",
      "    except Exception:\n",
      "        return None\n",
      "    # pySPM API differences across versions; attempt robust access\n",
      "    ThreeDS = None\n",
      "    for name in ('ThreeDS', 'threeDS', 'ThreeDs'):\n",
      "        if hasattr(pySPM, name):\n",
      "            ThreeDS = getattr(pySPM, name)\n",
      "            break\n",
      "    if ThreeDS is None:\n",
      "        # sometimes under pySPM.SPM\n",
      "        try:\n",
      "            from pySPM.SPM import ThreeDS as ThreeDS_alt\n",
      "            ThreeDS = ThreeDS_alt\n",
      "        except Exception:\n",
      "            pass\n",
      "    if ThreeDS is None:\n",
      "        print(\"pySPM does not provide a ThreeDS reader\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    try:\n",
      "        d = ThreeDS(path)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to read with pySPM: {e}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Acquire list of channels\n",
      "    channels = []\n",
      "    for attr in ('channels', 'Signals', 'signals', 'chs'):\n",
      "        if hasattr(d, attr):\n",
      "            try:\n",
      "                chs = getattr(d, attr)\n",
      "                if isinstance(chs, (list, tuple)):\n",
      "                    channels = list(chs)\n",
      "                    break\n",
      "                if isinstance(chs, dict):\n",
      "                    channels = list(chs.keys())\n",
      "                    break\n",
      "            except Exception:\n",
      "                pass\n",
      "\n",
      "    # Fallback: look for typical names\n",
      "    if not channels:\n",
      "        channels = ['Current (A)', 'I (A)', 'Current', 'LIY (A)', 'Z (m)', 'Topography (m)']\n",
      "\n",
      "    key = find_best_key(channels, prefer='current')\n",
      "    if key is None:\n",
      "        key = find_best_key(channels, prefer='topography')\n",
      "    if key is None:\n",
      "        print(\"No appropriate channel found via pySPM\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Get bias vector\n",
      "    bias = None\n",
      "    for attr in ('bias', 'V', 'voltages', 'spectroscopy_axis'):\n",
      "        if hasattr(d, attr):\n",
      "            try:\n",
      "                bias = np.array(getattr(d, attr)).astype(float).ravel()\n",
      "                break\n",
      "            except Exception:\n",
      "                pass\n",
      "    if bias is None:\n",
      "        try:\n",
      "            bias = np.array(d.get_bias()).astype(float).ravel()\n",
      "        except Exception:\n",
      "            pass\n",
      "    if bias is None:\n",
      "        print(\"Could not determine bias vector via pySPM\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Build a volume across bias by stacking maps for each bias point\n",
      "    try:\n",
      "        maps = []\n",
      "        for v in bias:\n",
      "            # different APIs: get_map(channel, bias=value) or get_map(channel, V=value)\n",
      "            arr = None\n",
      "            try:\n",
      "                arr = d.get_map(key, bias=float(v))\n",
      "            except Exception:\n",
      "                try:\n",
      "                    arr = d.get_map(key, V=float(v))\n",
      "                except Exception:\n",
      "                    pass\n",
      "            if arr is None:\n",
      "                # try getMap\n",
      "                try:\n",
      "                    arr = d.getMap(key, bias=float(v))\n",
      "                except Exception:\n",
      "                    try:\n",
      "                        arr = d.getMap(key, V=float(v))\n",
      "                    except Exception:\n",
      "                        pass\n",
      "            if arr is None:\n",
      "                print(f\"Failed to retrieve map for bias {v} via pySPM\", file=sys.stderr)\n",
      "                return None\n",
      "            arr = np.array(arr)\n",
      "            maps.append(arr)\n",
      "        vol = np.stack(maps, axis=2)  # Ny, Nx, Nz\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to construct volume via pySPM: {e}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    return {\n",
      "        'volume': vol,\n",
      "        'bias': bias,\n",
      "        'bias_axis': 2,\n",
      "        'channel_key': key\n",
      "    }\n",
      "\n",
      "def main():\n",
      "    path = os.path.join('.', 'stm_data_code_sample', '3D_hyperspectral_data', 'cits_data.3ds')\n",
      "    if not os.path.isfile(path):\n",
      "        print(f\"File not found: {path}\", file=sys.stderr)\n",
      "        sys.exit(1)\n",
      "\n",
      "    data = load_with_nanonispy(path)\n",
      "    if data is None:\n",
      "        data = load_with_pyspm(path)\n",
      "    if data is None:\n",
      "        print(\"Unable to load the 3DS file with available methods.\", file=sys.stderr)\n",
      "        sys.exit(1)\n",
      "\n",
      "    vol = data['volume']\n",
      "    bias = np.array(data['bias']).astype(float).ravel()\n",
      "    axis_bias = data['bias_axis']\n",
      "    key = data['channel_key']\n",
      "\n",
      "    # Find index closest to 1.2 V\n",
      "    target_bias = 1.2\n",
      "    idx = int(np.argmin(np.abs(bias - target_bias)))\n",
      "    actual_bias = float(bias[idx])\n",
      "\n",
      "    # Move bias axis to last position to index easily\n",
      "    if axis_bias != 2:\n",
      "        vol = np.moveaxis(vol, axis_bias, 2)\n",
      "\n",
      "    # Extract 2D map\n",
      "    try:\n",
      "        current_map = vol[:, :, idx]\n",
      "    except Exception as e:\n",
      "        print(f\"Error extracting 2D map at index {idx}: {e}\", file=sys.stderr)\n",
      "        sys.exit(1)\n",
      "\n",
      "    plt.figure(figsize=(6, 5))\n",
      "    im = plt.imshow(current_map, origin='lower', cmap='viridis', aspect='auto')\n",
      "    plt.colorbar(im, label=key)\n",
      "    plt.title(f\"{key} at bias {actual_bias:.3f} V (requested 1.2 V)\")\n",
      "    plt.xlabel('X pixel')\n",
      "    plt.ylabel('Y pixel')\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "[Step 3/3] ✓ Response received successfully!\n",
      "  Generated code length: 8714 characters\n",
      "\n",
      "===== GENERATED PYTHON CODE (STRING) =====\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def find_best_key(keys, prefer='current'):\n",
      "    # Rank available channel keys by preference\n",
      "    ranking = []\n",
      "    for k in keys:\n",
      "        lk = k.lower()\n",
      "        score = 0\n",
      "        if prefer == 'current':\n",
      "            if 'current' in lk:\n",
      "                score += 100\n",
      "            if ' i ' in f' {lk} ' or lk.startswith('i ') or lk.endswith(' i') or lk == 'i':\n",
      "                score += 80\n",
      "            if ' (a)' in lk:\n",
      "                score += 20\n",
      "            if 'liy' in lk or 'lockin y' in lk:\n",
      "                score += 10  # less preferred but acceptable\n",
      "        elif prefer == 'topography':\n",
      "            if 'topography' in lk:\n",
      "                score += 100\n",
      "            if lk.strip() == 'z' or lk.startswith('z ') or ' z ' in f' {lk} ':\n",
      "                score += 90\n",
      "            if 'height' in lk:\n",
      "                score += 80\n",
      "            if '(m)' in lk:\n",
      "                score += 10\n",
      "        ranking.append((score, k))\n",
      "    ranking.sort(reverse=True, key=lambda x: x[0])\n",
      "    best = ranking[0][1] if ranking and ranking[0][0] > 0 else None\n",
      "    return best\n",
      "\n",
      "def load_with_nanonispy(path):\n",
      "    try:\n",
      "        from nanonispy import read\n",
      "    except Exception:\n",
      "        return None\n",
      "    try:\n",
      "        g = read.Grid(path)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to read with nanonispy: {e}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Obtain bias vector\n",
      "    bias = None\n",
      "    for attr in ('bias', 'sweep_signal', 'spectroscopy_axis'):\n",
      "        if hasattr(g, attr):\n",
      "            try:\n",
      "                bias = np.array(getattr(g, attr)).astype(float).ravel()\n",
      "                break\n",
      "            except Exception:\n",
      "                pass\n",
      "    if bias is None:\n",
      "        # Attempt to fetch from header parameters\n",
      "        try:\n",
      "            params = getattr(g, 'params', {})\n",
      "            if 'Bias (V)' in params:\n",
      "                bias = np.array(params['Bias (V)']).astype(float).ravel()\n",
      "        except Exception:\n",
      "            pass\n",
      "    if bias is None:\n",
      "        print(\"Could not determine bias vector from 3ds using nanonispy\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Obtain signals dictionary\n",
      "    signals = None\n",
      "    if hasattr(g, 'signals'):\n",
      "        signals = g.signals\n",
      "    else:\n",
      "        # Some versions may expose channel data differently\n",
      "        cand = []\n",
      "        for attr in dir(g):\n",
      "            if attr.lower() in ('signals', 'channels', 'data'):\n",
      "                obj = getattr(g, attr)\n",
      "                if isinstance(obj, dict):\n",
      "                    signals = obj\n",
      "                    break\n",
      "                else:\n",
      "                    cand.append((attr, type(obj)))\n",
      "        if signals is None:\n",
      "            print(\"Could not find signals in nanonispy Grid object\", file=sys.stderr)\n",
      "            return None\n",
      "\n",
      "    keys = list(signals.keys())\n",
      "    key = find_best_key(keys, prefer='current')\n",
      "    if key is None:\n",
      "        key = find_best_key(keys, prefer='topography')\n",
      "    if key is None:\n",
      "        print(\"No appropriate channel (current or topography) found in 3ds\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    vol = np.array(signals[key])\n",
      "    # Expecting (Ny, Nx, Nz) or (Nx, Ny, Nz) or (Nz, Ny, Nx)\n",
      "    # Try to identify spectroscopic dimension by matching with bias length\n",
      "    vol_shape = vol.shape\n",
      "    dims = len(vol_shape)\n",
      "    if dims != 3:\n",
      "        print(f\"Unexpected data shape for channel '{key}': {vol_shape}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Determine which axis matches bias length\n",
      "    axis_bias = None\n",
      "    for ax in range(3):\n",
      "        if vol_shape[ax] == bias.size:\n",
      "            axis_bias = ax\n",
      "            break\n",
      "    if axis_bias is None:\n",
      "        # As fallback, if last axis matches common case, assume last axis is sweep\n",
      "        axis_bias = 2\n",
      "\n",
      "    return {\n",
      "        'volume': vol,\n",
      "        'bias': bias,\n",
      "        'bias_axis': axis_bias,\n",
      "        'channel_key': key\n",
      "    }\n",
      "\n",
      "def load_with_pyspm(path):\n",
      "    try:\n",
      "        import pySPM\n",
      "    except Exception:\n",
      "        return None\n",
      "    # pySPM API differences across versions; attempt robust access\n",
      "    ThreeDS = None\n",
      "    for name in ('ThreeDS', 'threeDS', 'ThreeDs'):\n",
      "        if hasattr(pySPM, name):\n",
      "            ThreeDS = getattr(pySPM, name)\n",
      "            break\n",
      "    if ThreeDS is None:\n",
      "        # sometimes under pySPM.SPM\n",
      "        try:\n",
      "            from pySPM.SPM import ThreeDS as ThreeDS_alt\n",
      "            ThreeDS = ThreeDS_alt\n",
      "        except Exception:\n",
      "            pass\n",
      "    if ThreeDS is None:\n",
      "        print(\"pySPM does not provide a ThreeDS reader\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    try:\n",
      "        d = ThreeDS(path)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to read with pySPM: {e}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Acquire list of channels\n",
      "    channels = []\n",
      "    for attr in ('channels', 'Signals', 'signals', 'chs'):\n",
      "        if hasattr(d, attr):\n",
      "            try:\n",
      "                chs = getattr(d, attr)\n",
      "                if isinstance(chs, (list, tuple)):\n",
      "                    channels = list(chs)\n",
      "                    break\n",
      "                if isinstance(chs, dict):\n",
      "                    channels = list(chs.keys())\n",
      "                    break\n",
      "            except Exception:\n",
      "                pass\n",
      "\n",
      "    # Fallback: look for typical names\n",
      "    if not channels:\n",
      "        channels = ['Current (A)', 'I (A)', 'Current', 'LIY (A)', 'Z (m)', 'Topography (m)']\n",
      "\n",
      "    key = find_best_key(channels, prefer='current')\n",
      "    if key is None:\n",
      "        key = find_best_key(channels, prefer='topography')\n",
      "    if key is None:\n",
      "        print(\"No appropriate channel found via pySPM\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Get bias vector\n",
      "    bias = None\n",
      "    for attr in ('bias', 'V', 'voltages', 'spectroscopy_axis'):\n",
      "        if hasattr(d, attr):\n",
      "            try:\n",
      "                bias = np.array(getattr(d, attr)).astype(float).ravel()\n",
      "                break\n",
      "            except Exception:\n",
      "                pass\n",
      "    if bias is None:\n",
      "        try:\n",
      "            bias = np.array(d.get_bias()).astype(float).ravel()\n",
      "        except Exception:\n",
      "            pass\n",
      "    if bias is None:\n",
      "        print(\"Could not determine bias vector via pySPM\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    # Build a volume across bias by stacking maps for each bias point\n",
      "    try:\n",
      "        maps = []\n",
      "        for v in bias:\n",
      "            # different APIs: get_map(channel, bias=value) or get_map(channel, V=value)\n",
      "            arr = None\n",
      "            try:\n",
      "                arr = d.get_map(key, bias=float(v))\n",
      "            except Exception:\n",
      "                try:\n",
      "                    arr = d.get_map(key, V=float(v))\n",
      "                except Exception:\n",
      "                    pass\n",
      "            if arr is None:\n",
      "                # try getMap\n",
      "                try:\n",
      "                    arr = d.getMap(key, bias=float(v))\n",
      "                except Exception:\n",
      "                    try:\n",
      "                        arr = d.getMap(key, V=float(v))\n",
      "                    except Exception:\n",
      "                        pass\n",
      "            if arr is None:\n",
      "                print(f\"Failed to retrieve map for bias {v} via pySPM\", file=sys.stderr)\n",
      "                return None\n",
      "            arr = np.array(arr)\n",
      "            maps.append(arr)\n",
      "        vol = np.stack(maps, axis=2)  # Ny, Nx, Nz\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to construct volume via pySPM: {e}\", file=sys.stderr)\n",
      "        return None\n",
      "\n",
      "    return {\n",
      "        'volume': vol,\n",
      "        'bias': bias,\n",
      "        'bias_axis': 2,\n",
      "        'channel_key': key\n",
      "    }\n",
      "\n",
      "def main():\n",
      "    path = os.path.join('.', 'stm_data_code_sample', '3D_hyperspectral_data', 'cits_data.3ds')\n",
      "    if not os.path.isfile(path):\n",
      "        print(f\"File not found: {path}\", file=sys.stderr)\n",
      "        sys.exit(1)\n",
      "\n",
      "    data = load_with_nanonispy(path)\n",
      "    if data is None:\n",
      "        data = load_with_pyspm(path)\n",
      "    if data is None:\n",
      "        print(\"Unable to load the 3DS file with available methods.\", file=sys.stderr)\n",
      "        sys.exit(1)\n",
      "\n",
      "    vol = data['volume']\n",
      "    bias = np.array(data['bias']).astype(float).ravel()\n",
      "    axis_bias = data['bias_axis']\n",
      "    key = data['channel_key']\n",
      "\n",
      "    # Find index closest to 1.2 V\n",
      "    target_bias = 1.2\n",
      "    idx = int(np.argmin(np.abs(bias - target_bias)))\n",
      "    actual_bias = float(bias[idx])\n",
      "\n",
      "    # Move bias axis to last position to index easily\n",
      "    if axis_bias != 2:\n",
      "        vol = np.moveaxis(vol, axis_bias, 2)\n",
      "\n",
      "    # Extract 2D map\n",
      "    try:\n",
      "        current_map = vol[:, :, idx]\n",
      "    except Exception as e:\n",
      "        print(f\"Error extracting 2D map at index {idx}: {e}\", file=sys.stderr)\n",
      "        sys.exit(1)\n",
      "\n",
      "    plt.figure(figsize=(6, 5))\n",
      "    im = plt.imshow(current_map, origin='lower', cmap='viridis', aspect='auto')\n",
      "    plt.colorbar(im, label=key)\n",
      "    plt.title(f\"{key} at bias {actual_bias:.3f} V (requested 1.2 V)\")\n",
      "    plt.xlabel('X pixel')\n",
      "    plt.ylabel('Y pixel')\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "rag_chain = get_rag_chain(\n",
    "    folder_path=folder_path,\n",
    "    persist_basename=persist_basename,\n",
    "    new_persist=new_persist,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    api_key=api_key,\n",
    ")\n",
    "print('✓ rag_chain created successfully')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INVOKING RAG CHAIN\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Task: {task[:100]}...\" if len(task) > 100 else f\"Task: {task}\")\n",
    "print(\"\\n[Step 1/3] Retrieving relevant documents from vector store...\")\n",
    "print(\"  ⚠️  WARNING: ChromaDB query on OneDrive may crash kernel here!\")\n",
    "\n",
    "try:\n",
    "    print(\"\\n[Step 2/3] Calling LLM to generate code...\")\n",
    "    print(f\"  Using model: {model}\")\n",
    "    print(\"  This may take 10-30 seconds depending on complexity...\")\n",
    "    \n",
    "    response_code_str = rag_chain.invoke(task)\n",
    "    \n",
    "    print(\"\\n[Step 3/3] ✓ Response received successfully!\")\n",
    "    print(f\"  Generated code length: {len(response_code_str)} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n❌ ERROR during rag_chain.invoke()!\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")\n",
    "    import traceback\n",
    "    print(\"\\nFull traceback:\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\"\\n===== GENERATED PYTHON CODE (STRING) =====\\n\")\n",
    "print(response_code_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85669cef",
   "metadata": {},
   "source": [
    "## Test the code\n",
    "Write the code to \"main_rag_test.py\". Overwrites if already exists.\n",
    "\n",
    "Test it by running \"python main_rag_test.py\" on terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75e8720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/zwx/Documents/RAG-for-SPM-data-analysis/main_rag_test.py')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_generated_code_to_file(\n",
    "    code_str=response_code_str,\n",
    "    prompt_str=task,\n",
    "    filename=\"main_rag_test.py\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon_rag (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
